{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (32,32,3)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "\n",
    "net = layers.Conv2D(32,(3,3), padding = 'SAME')(inputs)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(32,(3,3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2,2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Conv2D(64,(3,3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Conv2D(64,(3,3), padding = 'SAME')(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=(2,2))(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(512)(net)\n",
    "net = layers.Activation('relu')(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "net = layers.Activation('softmax')(net)\n",
    "\n",
    "model = tf.keras.Model(inputs= inputs, outputs=net, name = 'Basic_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate),\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob('cifar/train/*.png')[:1000]\n",
    "test_paths = glob('cifar/test/*.png')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(path):\n",
    "    return path.split('_')[-1].replace('.png','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [get_class_name(path) for path in train_paths]\n",
    "class_names = np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    fname = tf.strings.split(path, '_')[-1]\n",
    "    lbl_name = tf.strings.regex_replace(fname, '.png','')\n",
    "    onehot = tf.cast(lbl_name == class_names, tf.uint8)\n",
    "    return tf.argmax(onehot) # label번호를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_label(path):\n",
    "    gfile = tf.io.read_file(path)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.cast(image, tf.float32) / 255.\n",
    "    \n",
    "    label = get_label(path)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(image, label):\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls = AUTOTUNE)\n",
    "train_dataset = train_dataset.map(image_preprocess, num_parallel_calls = AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.shuffle(buffer_size = len(train_paths))\n",
    "train_dataset = train_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_paths)\n",
    "test_dataset = test_dataset.map(load_image_label, num_parallel_calls = AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "test_dataset = test_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### history 들여다보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-1139268ebccc>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 2.2981 - accuracy: 0.1074 - val_loss: 2.2477 - val_accuracy: 0.1149\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 2.2410 - accuracy: 0.1601 - val_loss: 2.2296 - val_accuracy: 0.2379\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 2.1788 - accuracy: 0.2025 - val_loss: 2.1251 - val_accuracy: 0.2208\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 2.1531 - accuracy: 0.1994 - val_loss: 2.0899 - val_accuracy: 0.2359\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 4s 116ms/step - loss: 2.0611 - accuracy: 0.2417 - val_loss: 2.0227 - val_accuracy: 0.2621\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 2.0211 - accuracy: 0.2440 - val_loss: 2.0714 - val_accuracy: 0.2581\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 2.0004 - accuracy: 0.2624 - val_loss: 1.9482 - val_accuracy: 0.3014\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 4s 115ms/step - loss: 1.9390 - accuracy: 0.2617 - val_loss: 1.9193 - val_accuracy: 0.3085\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 1.9011 - accuracy: 0.2872 - val_loss: 1.9221 - val_accuracy: 0.3034\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 1.8822 - accuracy: 0.2661 - val_loss: 1.9209 - val_accuracy: 0.2833\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 1.8385 - accuracy: 0.3275 - val_loss: 1.9781 - val_accuracy: 0.2974\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 4s 115ms/step - loss: 1.8393 - accuracy: 0.2945 - val_loss: 1.8287 - val_accuracy: 0.3185\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 1.8193 - accuracy: 0.2944 - val_loss: 1.7475 - val_accuracy: 0.3679\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 4s 119ms/step - loss: 1.7716 - accuracy: 0.3378 - val_loss: 1.7365 - val_accuracy: 0.3831\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 1.7351 - accuracy: 0.3528 - val_loss: 1.6913 - val_accuracy: 0.3881\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 1.6628 - accuracy: 0.3812 - val_loss: 1.6742 - val_accuracy: 0.3871\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 1.7043 - accuracy: 0.3760 - val_loss: 1.6783 - val_accuracy: 0.3861\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 1.6584 - accuracy: 0.3688 - val_loss: 1.6645 - val_accuracy: 0.3982\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.6389 - accuracy: 0.4089 - val_loss: 1.6753 - val_accuracy: 0.3891\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 1.5581 - accuracy: 0.3977 - val_loss: 1.7214 - val_accuracy: 0.3982\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.6094 - accuracy: 0.4032 - val_loss: 1.6697 - val_accuracy: 0.4123\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.5531 - accuracy: 0.4132 - val_loss: 1.6563 - val_accuracy: 0.4012\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.5238 - accuracy: 0.4411 - val_loss: 1.6338 - val_accuracy: 0.3992\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 1.5672 - accuracy: 0.4174 - val_loss: 1.6380 - val_accuracy: 0.4012\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.4861 - accuracy: 0.4819 - val_loss: 1.5992 - val_accuracy: 0.4214\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 1.5116 - accuracy: 0.4597 - val_loss: 1.6929 - val_accuracy: 0.3931\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.4506 - accuracy: 0.4804 - val_loss: 1.6662 - val_accuracy: 0.3851\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 1.4215 - accuracy: 0.4849 - val_loss: 1.5993 - val_accuracy: 0.4395\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 1.4466 - accuracy: 0.4680 - val_loss: 1.6091 - val_accuracy: 0.4446\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 4s 128ms/step - loss: 1.3624 - accuracy: 0.4804 - val_loss: 1.5803 - val_accuracy: 0.4304\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 1.3581 - accuracy: 0.5062 - val_loss: 1.6056 - val_accuracy: 0.4516\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 1.3676 - accuracy: 0.4959 - val_loss: 1.5649 - val_accuracy: 0.4446\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 1.3259 - accuracy: 0.5269 - val_loss: 1.6834 - val_accuracy: 0.4315\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.3997 - accuracy: 0.5134 - val_loss: 1.6936 - val_accuracy: 0.4032\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.3197 - accuracy: 0.5181 - val_loss: 1.5527 - val_accuracy: 0.4536\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 4s 121ms/step - loss: 1.2192 - accuracy: 0.5498 - val_loss: 1.5758 - val_accuracy: 0.4798\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 4s 127ms/step - loss: 1.2812 - accuracy: 0.5155 - val_loss: 1.5482 - val_accuracy: 0.4748\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.2398 - accuracy: 0.5300 - val_loss: 1.5387 - val_accuracy: 0.4778\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.2067 - accuracy: 0.5455 - val_loss: 1.5723 - val_accuracy: 0.4556\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 1.2229 - accuracy: 0.5486 - val_loss: 1.6565 - val_accuracy: 0.4304\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.2511 - accuracy: 0.5300 - val_loss: 1.5248 - val_accuracy: 0.4577\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.1447 - accuracy: 0.5888 - val_loss: 1.5637 - val_accuracy: 0.4788\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.2117 - accuracy: 0.5579 - val_loss: 1.5532 - val_accuracy: 0.4536\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 4s 126ms/step - loss: 1.1228 - accuracy: 0.5826 - val_loss: 1.4945 - val_accuracy: 0.4879\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 4s 125ms/step - loss: 1.0671 - accuracy: 0.6169 - val_loss: 1.5893 - val_accuracy: 0.4516\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 4s 123ms/step - loss: 1.1388 - accuracy: 0.6070 - val_loss: 1.6316 - val_accuracy: 0.4587\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 4s 129ms/step - loss: 1.0971 - accuracy: 0.6038 - val_loss: 1.5058 - val_accuracy: 0.4869\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 4s 122ms/step - loss: 1.0207 - accuracy: 0.6260 - val_loss: 1.6032 - val_accuracy: 0.4798\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 4s 120ms/step - loss: 1.0431 - accuracy: 0.6102 - val_loss: 1.5547 - val_accuracy: 0.4788\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 4s 124ms/step - loss: 1.0570 - accuracy: 0.6136 - val_loss: 1.5372 - val_accuracy: 0.4778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16d79b14dc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = len(train_paths) //batch_size\n",
    "validation_steps = len(test_paths) // batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    train_dataset,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_data = test_dataset,\n",
    "    validation_steps = validation_steps,\n",
    "    epochs = num_epochs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cifar/test\\\\0_cat.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = test_paths[0]\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile, dtype=tf.float32)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image[tf.newaxis,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator에서 데이터를 가져오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 32, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0044678 , 0.00158701, 0.01123246, 0.1049071 , 0.16934122,\n",
       "       0.1176418 , 0.0218003 , 0.51319873, 0.00291123, 0.05291233],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator에 넣는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgVUlEQVR4nO2de2yc55XenzM3zpAc3kSJpEhZlGVavsi27FV8iRzn4sTxerN1DDRp0iLwH+lqC6yLGNiicFOgSYv+4SyaLFygCKBsjDgLN4nRJIg3Td11vV4bu4kv8lW25YskkzLFm0iK98vcTv/geCE77/ORNsWhku/5AQJH75kz3zvvfGe+mfeZc465O4QQv/8kNnsCQojaoGAXIiYo2IWICQp2IWKCgl2ImKBgFyImpNbjbGa3ArgPQBLAX7n7vVH3b2zMe9uWdvJY3K9SqQTHM2k+/Xw+T23FYiHiWFyKTFgxOL68zB9vcXGJ2pIJ/qQrHn7OAABLcr9yeP65XC7i8fh7frlcirCVqc3L4TWZPDNDfSKWA4tL4bUHgJbWpgjbluB4U1Mz9YlSo5eXFqmNnacAkMlkqC2ZDL+ebBwAmGR+8uRJjI+PB1fyQwe7mSUB/A8AnwEwCOBZM3vY3V9jPm1b2vHv/8N/Cdoinhdd4K6u8AsJADd/8pPUNjR0ktqiTqpc8lRw/PiJd6jPqy+9QW1NeX4CLBbmqS2R5Cf37NxycHzv3iupDxL8jWBuZpLaJmenqK04G16rH/3kEerTWMej/dU3hqntj277OLXd/s//VXD8U5/5Y+pTLvE3sbdep6c3FhYWqK13Rw+1tbSG33gaGvgFq1IJz/HGAx+jPuv5GH8tgGPufsLdCwB+DOD2dTyeEGIDWU+wdwM4+5I2WB0TQpyHrCfYQ5+5fuuLhJkdNLPDZnZ4bm52HYcTQqyH9QT7IIAdZ/2/B8DQ++/k7ofcfb+7729s5N9BhBAby3qC/VkAfWa2y8wyAL4E4OFzMy0hxLnmQ+/Gu3vJzO4C8H+xIr3d7+6vRvkYHGmEd7stQv7p6twWHO/ruyjiYFwGGRjgO7v5xjpq29qVDo6/08939+cX+K761dffQG3pCHnijdefpbbx0ang+MzkCJ/HR/k8jh/lUpMbP30SjQ3B8Xvv+yPq8/jj/4/aSrmnqC2V4mrCTTcdCD9egUuKTY311LYlQuZ74fDT1NZ34S5qy+cbg+MeIQMnk2HlIkrCXpfO7u6/AvCr9TyGEKI26Bd0QsQEBbsQMUHBLkRMULALERMU7ELEhHXtxn9QLJFAhmRfFQo8O2zgxIngeF8flzMSxmWLzq42aksbT4I4PfR2cHx2YZr6NG65gNrePs7lsHyO/9pw69Yd1JbNhJMq3n6Lq6LdO3upreMCbutOc3nw9Om54Hh9mmtD/+yzn6W2i3r7qK2tOSxdAYCXwolByRSXZlMR+lV3dwe1XXPNFdRWlw3LtgCQSISvuUbGAaBS4dIhPc4H9hBC/E6iYBciJijYhYgJCnYhYoKCXYiYUNPd+HLZcWY2XJssG1GAbJCUkRoeGaU+ey7ZTW2X7NlDbUsRO+uvjb0SHJ+Y5u+ZvXu6qM0KZ6jt6GtvUtvl14STOwCga3t4p76puYX6pNJ8NzuZ4kkhluYJKI0N4YSnualwuarVmJr8rezpf6IpzxOi0pnwHFMpvjtejKi7l0rxRKlLLruM2sz58QqFcEwkElHhyVUjhq7sQsQEBbsQMUHBLkRMULALERMU7ELEBAW7EDGhtokwZkgnwskTs1Onqd+FO8PJB2+9HpbCAOCiXTxZpKubd5Ipl3nNtZGJcOJKpcLlmFSEdLWzK0ttXe3cNse7TWFmNiwbbWnlj7dc4kk3iQWeMJI13iagsyecuDJTz7vgDAyEE54AYOeuS6htuRhRqy0VTrAqlfnrkszwsChHtPqanubrWJcJ1+QDgLps+PxZXuIycKYu/Hr6b1dz/yd0ZRciJijYhYgJCnYhYoKCXYiYoGAXIiYo2IWICeuS3sysH8AsVlJwSu6+P+r+pWIRE2Nh+Wpi7Dj123t5b3D8kUcfoz4vvvQitd39ta9R22sv/4ba5icWguNd7Txjr1zkUs0CeH261u08W644OsEfk+hyc7NcUpxZ5Flexflj1HbRFa3UliiHM/oqBS4NLS9xCbOthUt2/QO8vt7J4+E1TuR4W67mlq3UliFtl4BAC+OzSGf4c2NdntzD9fMAoFwk9f+cz+Jc6OyfdPfxc/A4QogNRB/jhYgJ6w12B/C3ZvacmR08FxMSQmwM6/0Yf8Ddh8xsG4BHzex1d3/y7DtU3wQOAkBzRLUUIcTGsq4ru7sPVf+OAfg5gGsD9znk7vvdfX99PS9/JITYWD50sJtZg5nl370N4BYAPDNFCLGprOdjfAeAn9tKq5wUgP/p7o9EORSLixg8FX4/SCT5VP7uibAc1tHZQ316Lr6a2t48xWWXl4/2U9vll+0MjmdHBqlP8QyXhcaKPKtpfitvd7Q4zedfngsLI3POM7JSdVxCa8qH20kBwOmxcCFQAJgaC0t9x05widWy4fUFgO0791FbD1cwMXY6/Lx3XshbgB0/Fm7zBQCXXHIxtU3NzFBba2sntc3OhyXd+oiimKlEWGLjwuA6gt3dTwC46sP6CyFqi6Q3IWKCgl2ImKBgFyImKNiFiAkKdiFiQk0LTjY1NeGWz3wmaFsc5bLFs8fCmVe3/uEt1Ge+xLOMWht4ZlDHFt6/bGE6LGtlI+SpxTnezy1R5tJbefxFasP8GDUZKeiZqWuiPqUiz2OaHueFQBeWeTHKRHZbcLyn72bqk2viczw1xud4SR8vRtmSC7/Wp4e5bPjMU1wuXZzlGYd9EbLc4CCX85qa2oPjKeOZfuksKSBq/PqtK7sQMUHBLkRMULALERMU7ELEBAW7EDGhprvxheUiBk+Ed5I7t7ZQv+6d4d3WwVOnqM/2nouo7c3Dj1NbochrtSXITnc9ytSnPqLtjxv3KzmvC4c0VwxyqfBLGvFoSKYi6qOB10Grr+eJGovFcNulZJLPfSmitVJLI1c8jrz0PLVt3Rbe6W7K853ujnbe1uqd/n5qa2zgKdxtW/j863LhuUxMTFKfbC48x4gSdLqyCxEXFOxCxAQFuxAxQcEuRExQsAsRExTsQsSEmkpvFQBLRG46PsKTOzouuDA4Xp/h8kkuw2WtgeFhamuI8Es21AfH5xd4QstikUtXLGkFALIZkugAwCPeoxcr4Zpr9Q08ySQXUfW3ECEBFiOeW0NdeI7DA4f5PFp6qa27bzu11RlvlXWU1JPbfkFE660eXtuwc9sfUNvgSV5fL5kNnzsA0FoOr3FLawv1mZ6eCo6Xy/z81ZVdiJigYBciJijYhYgJCnYhYoKCXYiYoGAXIiasKr2Z2f0APgdgzN33VsfaAPwEQC+AfgBfdHdebO3dx4LBEuGsp2tu3E/9To8OBcfbO7gcUy7zFkk7LuQZcXNnRqltaDxcf6x3B5dqGlK8tl6xzLO88jmeUZZr4lJToRiWXqJkskyE9JZtaKG2+RkuOZZK4ezB5FL4tQSAZIFnhp0a5Olcbc38mpUnmXkjA3wePX/Az4+W1i3UNtDP24Cl0lwmnp6eC45nczxDcHoiXBuwVOJS6Vqu7D8AcOv7xu4B8Ji79wF4rPp/IcR5zKrBXu23/v7E2tsBPFC9/QCAz5/baQkhzjUf9jt7h7sPA0D1b7husBDivGHDN+jM7KCZHTazw/Pz4e8mQoiN58MG+6jZyg+Sq3/pD9vd/ZC773f3/Q0RZXuEEBvLhw32hwHcWb19J4BfnJvpCCE2irVIbz8C8AkA7WY2COAbAO4F8JCZfRXASQBfWMvBSpUKpubCH+WXClxaqZQsOD4dIZOVi1yCWJjlXye6d4Uz7ADg6BsnguOHnzlCfW78xHXU1tvZSm0F0moKADwVzmwDACdrxYplAsDCXLg4JADkcjz7Lk2KWwJAcYHIikUuNy7NvElt9XW7qG0hxTP6FqfD8uDIIM+ynOnhz7lU5LbUMn9dpsbCrwsAdO0NS6mZOi6/enM+OJ5M8uv3qsHu7l8mJt60Swhx3qFf0AkRExTsQsQEBbsQMUHBLkRMULALERNqWnAynTR0toYPmSfFHAGgMB2WIOZmeGbb/AKXQX7wgx9S2xf/xeep7foDnwqOz8z9b+qzvMwLAE6enqK2xBLPKMsm+MvmpHhhucKlzURE77jFdMQpEtGbrVipBMczKS4BlpZ4n72lmXCWFwBYmj+mkYKZxQI/1tgk77HWUOLZch153tdvZIxLfUdfeyE4vnfv1dQnUxd+zmZc4tOVXYiYoGAXIiYo2IWICQp2IWKCgl2ImKBgFyIm1FR6KxUrmBgOy2VPPvoI9evtCRfCWSry96pyhUsQpYjiiz9+8MfUdvDfHAyO3/Vv/5T6PP3kk9Q2McWLUaYqXNbqStZRW7kcltjKzh/PIooUFqIkOyLzAUAyHZZLPeKMM+ev2eIil1kzEfNgmWOJBD935maL1NbVzdd+kmTYAYAZf+Ljp8N+z/7j09Tntdd+HRyfGOcSpa7sQsQEBbsQMUHBLkRMULALERMU7ELEhJruxnvFUZwP75xOT/MEg/Ght4LjHdt526XO7t3UtntXN7W9/Aqvg3bfd/57cPxrd/9r6nPppX3UdnxggNpmJ7higExEIkwhnCBRidgGL5R4sk5U2yID36kn+ScoFsMJMgCQbgjXVQOASsTu+ewsr6GXsPB6NDTxYzXmeYunXRdeQG2Tp/lrVirxHf7CdDjxpiHP691dfVW4XVp9/UPUR1d2IWKCgl2ImKBgFyImKNiFiAkKdiFigoJdiJiwlvZP9wP4HIAxd99bHfsmgD8B8O6v7r/u7r9a7bEqXsZ8YSpo6yDtbABgZnEhOD46fob6zM2E63oBQDYTUQetxKWh0alwXbtvfesQ9bnjjz9GbVu38fZPuSyXXZYWoxIumMTDJbSK8eSORIbbKssRLbtIa6hsI2/umd8aboMEAPOTE9Tmzq9ZLa3h1lANuWbqU4lKDJrjtQ1zdbwG3XOvvUJtW3Nh6dMSLdSneQtp/xRR428tV/YfALg1MP6X7r6v+m/VQBdCbC6rBru7PwmAl9sUQvxOsJ7v7HeZ2ctmdr+Z8c+jQojzgg8b7N8FsBvAPgDDAL7N7mhmB83ssJkdXoyoCy6E2Fg+VLC7+6i7l929AuB7AK6NuO8hd9/v7vtzWd6MQAixsXyoYDezs7dN7wDAtxqFEOcFa5HefgTgEwDazWwQwDcAfMLM9gFwAP0AeBG2s0gAYILSUplnBeWy4dZQ83PcZ2LyKLVVIo7VkOVy0hmSQTU+zeWYX/zyMWq79RYuy133MfphCfX14bpqANBF5LyZaV7vbmSMZ2tVShEZdqTFEwAYwraGRr69Ywt8jsWIWnipJS7LoTks9aWzW/mxCmGpFwAG3uaZilOzvE5eJcmlzxnSsmlxeo76WCo8x0pEPb5Vg93dvxwY/v5qfkKI8wv9gk6ImKBgFyImKNiFiAkKdiFigoJdiJhQ04KTgCORCEsyaeMyzsmhkeD48BgvUnn5nhZqa2vbS22Dp05x20j4F4AJ4++ZxhUjPPvMy9TW2NpObZfu6aW2dxbCMmBzPc+i69nBCywulsKyJwCcGeqntjTC7abSEQsyOcMLR+bS3M9y/Lk1tIXXMZvfSX3OTHEJbXCYFyTtjVjHXFMnt+XCPzZLJHkG21svPREcLxa59KYruxAxQcEuRExQsAsRExTsQsQEBbsQMUHBLkRMqG2vN1RQKoflq/Qil116tocLERaLPCsok+UyyIV9V1Pb4BiXXV5565fB8QRrbAYg38CXeHaGZ3k9+Nd/Q2133H4TtbW1hmWc9oZw4UUA6Ni+g9py7VGSEZflMslwtlmxGJbkAKCuyAtpprM8W65Q4rLcwny4KOmuS6+nPg1NXAaeW+Bz7Ojka5yr5/Nvag6fq4PDXAZu3tIbHE+mIoqHUosQ4vcKBbsQMUHBLkRMULALERMU7ELEhJruxidhaEyG622NzfC6X42ZluD4R67mCS3p+rAPACxFJKdccd0BahtfCi/XM3/3f6hPKaLeXYKsBQAsFrjfkRd4fb3rP74/OP56/9vUZzniWBc4X6xyhdfCS7SEd/HLs/3UJ5Pl7ZPmp6eorWHLdj4P0tqqsMDr7tVleFikEvw5D42MU9vs7Bi1Xbkv/JqdGeM+2zvCNfTSaT53XdmFiAkKdiFigoJdiJigYBciJijYhYgJCnYhYsJa2j/tAPBDAJ0AKgAOuft9ZtYG4CcAerHSAuqL7h7OOqhSrFQwMhtOhKlL8qaPS4vh5JTJGS4ZvXnkOLXt3HsdP9YSl2QOfPyjwfEsqSEGADNDx6gttXia2sanuFSWBH/e/UfDz/tjt93K5+H88QYHeTJGxwWXUNs0aRvV0sxr6y3O8cSmQoLXY9ve1kxtS5WwXy6izZcneVhs29pCbYsLZWrbuauH2hKkLl/b1m3UZ3DgjeB4scATjdZyZS8B+HN3vxTA9QD+zMwuA3APgMfcvQ/AY9X/CyHOU1YNdncfdvfnq7dnARwF0A3gdgAPVO/2AIDPb9AchRDngA/0nd3MegFcDeBpAB3uPgysvCEA4J85hBCbzpqD3cwaAfwUwN3uzqsu/LbfQTM7bGaHl5Z4gQohxMaypmA3szRWAv1Bd/9ZdXjUzLqq9i4AwR/yuvshd9/v7vuzWV7MXwixsawa7GZmWOnHftTdv3OW6WEAd1Zv3wngF+d+ekKIc8Vast4OAPgKgCNm9mJ17OsA7gXwkJl9FcBJAF9Y7YHq6rLY1XdZ0DYxMUX9cvVhOawhH65zBgB7r9hNbU0dXAZ54aXnqC3fEM542ntl+DkBQN1HeL274df/kdp27LqY2sopLht1t4fXpDI3SX1ml3nG4ehIuPUWAPRe/hFqM9Lmq5Lkddomhng7r/oW/lrPR2Ww5cOv9ZkzfD1y9Xz7qbm1hdoGB7jcu6UlT20Tk2Hpc3kpLFMDwLau8PNKpXlW3qrB7u7/AIDlYt68mr8Q4vxAv6ATIiYo2IWICQp2IWKCgl2ImKBgFyIm1LTgZKkCjC+GN/Yryaj3nbA0UfEW6lFHMokAoLTACwNmwH/lNzYWlqE68rxQYraxl9pu/PS/pLbKPM+Wy+V5K6Hxqdng+PzgAPUZGh6ktpde43LYFddwW66lOzh+auAE9alL8bZLu3bvorYjR05S2/UX3RAc9wrPDtvSztd3YoLPsf/4m9TWs51LYslEWOo7PTZBfcbJwxUKvBWZruxCxAQFuxAxQcEuRExQsAsRExTsQsQEBbsQMaGm0pvDUSmRDLZ63vestByW3goF/l5VXOIZSAvTXdRm4BJJfTqcudSxo4/6NETIcmdOj1KbJ3iW1KnTXDrM1oWzwxp3XEV9enPhvmwA0HnJp6ntmeeepLar9oVf521bWqhP31V8ji/8+glqe+Rv+DyGRqaC49dczY9lSZ5hN3CCS6KdXVv4YxoPtScefzQ4fsEOnvmYzmSC45UKl5x1ZRciJijYhYgJCnYhYoKCXYiYoGAXIibUdDe+UgEWl8KJBM31PMEg2xBu71OJaNNTLvL3sXeGjlLbzov5Lu0NHw1X4Rod5okYx97gx0o4f8755jZqa2vliRoZUoNsKqK1UkcHP1YioqNXZ7KX2rb3bA+OLxhXJ/7iv95LbS88xWsDfuVLn6O2iy4K1yJsznO1I+O8pt2Ve7jy8mqSJ9fMz0xT2w3X7wuODwzwiu25+vrg+Ep92DC6sgsRExTsQsQEBbsQMUHBLkRMULALERMU7ELEhFWlNzPbAeCHADoBVAAccvf7zOybAP4EwOnqXb/u7r+KeqyEObKZsNyUJHXmAODM1OngeEMzbxTZsm0Hte2q4y2I+vZcSW0njr0SHD918m3q00BkQwDY0srn0dTKkypS6XASBACUK+Eaes35sFQDAFOnnqW2/hNcVsxE9Omsy4WTSZ74zdPUZ/eeA9R23Q2fpbZd3TyRp7cvnExSWOatlZIJfi5OjgX7lwIA8jkuK05Pz1Nbz/bwOXJmmsto9Y0twfFEIkl91qKzlwD8ubs/b2Z5AM+Z2btpOn/p7v9tDY8hhNhk1tLrbRjAcPX2rJkdBRAuHSqEOG/5QN/ZzawXwNUA3v0sdpeZvWxm95sZ/1mXEGLTWXOwm1kjgJ8CuNvdZwB8F8BuAPuwcuX/NvE7aGaHzezw4iJvDSyE2FjWFOxmlsZKoD/o7j8DAHcfdfeyu1cAfA/AtSFfdz/k7vvdfX8uxzeJhBAby6rBbiu/rP8+gKPu/p2zxs+u7XQHgPBWtRDivGAtu/EHAHwFwBEze7E69nUAXzazfQAcQD+AP131YElDW0tYNkomeFZQa+fe4Hh9A3+vmpuJyPLa1kNtkxO85c7Iqf7geC7L69a1b+MZZRftCmdkAcCxt7nktWcPl5qGx4bD8+hspz6Ly7y10iWdPAuwuBA+FgCcHA23lNp9xT7q093N57G9J9wiCQBG3uEtpZ47/Hxw/KabPkZ9igs82yyV4Z9OCwUu2Q0O8fO7XAifqxNTOeqzUA7rnqUyz6Rcy278PwAICX6RmroQ4vxCv6ATIiYo2IWICQp2IWKCgl2ImKBgFyIm1LTgpFkF6VT4V3TLBT6VKdL+qSPLZa1kRPG/gXd4a6jGJt4aimVDJZI806ixaSu1FSr8OWcjMqgKRV4QMUcy+k4NnaI+5Yg2WqjwgpOFiKKedfXh512qcGloYY63tTpxbJbasim+/lNT4RZbb/e/RX16O/lrhgrPRJuf478QLZVL1DYyHn7eddlw0U4A6OgMS5EpUnAU0JVdiNigYBciJijYhYgJCnYhYoKCXYiYoGAXIibUVHpLphLY0loXtD35VDhLCgC27QwXXxwe5VLNVl7nEcbVHywtTFJbPemvVSrzbCeDU1tznmc1jQ1HSDXD/HmnU2FpqDAzEuHDT4NkihfFnCnyIor1jeHXrC6iv11DM89sSye5X11E5cvLLr8sOP7Ur/+e+pSu+gi1jUzybMp8O8+mtIjr6sxM+By5+VqeBTg8Gj5PvcLPG13ZhYgJCnYhYoKCXYiYoGAXIiYo2IWICQp2IWJCTaW35aVlvHGsP2xbLlO/+TNh2WjbtnA/MQCA8X5objxzySOyk0qFcCZdMsWP1ZDjGVnNeS4ZpVL8fXjyzBS1ZdJhiarInxbmF/naW0RRyUyGy3KZuvCplUzxrKzliLXP1eepbW6By2FZC8uiF+y4kPr0j3KZsrM3XPwUABbnwn32ACCV5M+7WAyfjyNDXI5+Zyj8mhUKPCNSV3YhYoKCXYiYoGAXIiYo2IWICQp2IWLCqrvxZpYF8CSAuur9/5e7f8PM2gD8BEAvVto/fdHdecEyAOWKYXo2vDudz7dQv8v29BIfnu1y9I03+EQi3uISEfXMSpXwbmspou1Pf/871FaX5XXmtnbtoLbliDpoZ0b7g+PlEt/pzuZ5a6hKxO5uQyNXQybHx4LjOZJMtALfVZ+ZOE1tTU18HikL14XbGrGrXirwtcrU8eSl6YjWYZbmfi3t4Zp3A2/zOnlbtoXVhIhyiGu6si8D+JS7X4WV9sy3mtn1AO4B8Ji79wF4rPp/IcR5yqrB7iu8+5abrv5zALcDeKA6/gCAz2/EBIUQ54a19mdPVju4jgF41N2fBtDh7sMAUP3Lk5GFEJvOmoLd3cvuvg9AD4BrzYx/4XkfZnbQzA6b2eHFJf4LIyHExvKBduPdfQrA3wO4FcComXUBQPVvcEfG3Q+5+35335/L8p+HCiE2llWD3cy2mllL9XYOwKcBvA7gYQB3Vu92J4BfbNAchRDngLUkwnQBeMDMklh5c3jI3X9pZr8B8JCZfRXASQBfWO2Bsrl6XL53X9DW3h6uWQYAo6PhZIxXXuXSxHJhMWImvC5cKcmTWurS4cSPUpkfK5MJ19wDgFyGH2tolEtN6Sh5sBxOhKmUebJLGVxqSiW5ZDS/yGvQpevDa1VO8FpyyYj6dIkETySZWYhoh9UabhG2u+9i6nNmItwyCgDe7A9LigBgRJoFACvzdmSVSvg88BKXWHf0hOXSTET7p1WD3d1fBnB1YHwCwM2r+Qshzg/0CzohYoKCXYiYoGAXIiYo2IWICQp2IWKCuXMZ6pwfzOw0gIHqf9sB8D5GtUPzeC+ax3v5XZvHTncPptHVNNjfc2Czw+6+f1MOrnloHjGchz7GCxETFOxCxITNDPZDm3jss9E83ovm8V5+b+axad/ZhRC1RR/jhYgJmxLsZnarmb1hZsfMbNNq15lZv5kdMbMXzexwDY97v5mNmdkrZ421mdmjZvZW9W/rJs3jm2Z2qromL5rZbTWYxw4ze9zMjprZq2b2tep4TdckYh41XRMzy5rZM2b2UnUe/7k6vr71cPea/gOQBHAcwIUAMgBeAnBZredRnUs/gPZNOO5NAK4B8MpZY38B4J7q7XsAfGuT5vFNAP+uxuvRBeCa6u08gDcBXFbrNYmYR03XBIABaKzeTgN4GsD1612PzbiyXwvgmLufcPcCgB9jpXhlbHD3JwFMvm+45gU8yTxqjrsPu/vz1duzAI4C6EaN1yRiHjXFVzjnRV43I9i7AZxdTH0Qm7CgVRzA35rZc2Z2cJPm8C7nUwHPu8zs5erH/A3/OnE2ZtaLlfoJm1rU9H3zAGq8JhtR5HUzgj1UfmOzJIED7n4NgD8E8GdmdtMmzeN84rsAdmOlR8AwgG/X6sBm1gjgpwDudveZWh13DfOo+Zr4Ooq8MjYj2AcBnN3upAfA0CbMA+4+VP07BuDnWPmKsVmsqYDnRuPuo9UTrQLge6jRmphZGisB9qC7/6w6XPM1Cc1js9akeuwpfMAir4zNCPZnAfSZ2S4zywD4ElaKV9YUM2sws/y7twHcAuCVaK8N5bwo4PnuyVTlDtRgTczMAHwfwFF3/85ZppquCZtHrddkw4q81mqH8X27jbdhZafzOID/uElzuBArSsBLAF6t5TwA/AgrHweLWPmk81UAW7DSRuut6t+2TZrHXwM4AuDl6snVVYN53IiVr3IvA3ix+u+2Wq9JxDxquiYArgTwQvV4rwD4T9Xxda2HfkEnREzQL+iEiAkKdiFigoJdiJigYBciJijYhYgJCnYhYoKCXYiYoGAXIib8fxIuVRR7f70fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in test_dataset.take(1): # 배치 갯수 정하기\n",
    "    print(image.shape)\n",
    "    plt.imshow(image[31])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_dataset.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-52a493015e41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "image, label = test_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 1.6492 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6491848230361938, 0.5]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(image,label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
